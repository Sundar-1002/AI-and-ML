---
title: "Machine learning and AI - Assignment 1"
author: "Sundararajan Srinivasan"
format: pdf
editor: visual
---

# Exercise 2:

# Q1.

## Multinomial logistic regression classifier + PCA dimension reduction with Q coordinate vectors.

```{r, warning=FALSE}
library(nnet)
set.seed(101)
```

```{r}
load("data_assignment_1_bats.RData")
```

We take **20**% of the total data as **test** data and **80**% of total data as **train and validation** data.

```{r}
n = nrow(data_bats)
test = sample(1:n, n*0.2)
data_test = data_bats[test,]
```

```{r}
train = setdiff(1:n, test)
copy_train = train
data_train_and_validation = data_bats[train,]
n_train = nrow(data_train_and_validation)
n_col = ncol(data_bats[,-1])
```

Scaling data before PCA ensures that **all features contribute** **equally** to the **variance**, **preventing** **features** with **larger magnitudes** from **dominating** the principal components.

```{r}
x_scale = scale(data_train_and_validation[,-1])
data_train_and_validation[,-1] = x_scale

data_test[,-1] =  scale(data_test[,-1], 
                        center = attr(x_scale, "scaled:center"), 
                        scale = attr(x_scale, "scaled:scale"))
```

```{r}
K = 5
accuracy_matrix = matrix(0, nrow = K, ncol = 50)
variance_matrix = matrix(0, nrow= K, ncol = 50)

folds = rep(1:K, ceiling(n_train/K))
folds = sample(folds)
folds = folds[1:n_train]
for (k in 1:K) {
  k_train = which(folds != k)
  k_validation = setdiff(1:n_train, k_train)
  
  x_train = data_train_and_validation[k_train,-1]
  y_train = data_train_and_validation[k_train,1]
  y_train = as.factor(y_train)
  
  x_validation = data_train_and_validation[k_validation,-1]
  y_validation = data_train_and_validation[k_validation,1]
  y_validation = as.factor(y_validation)

  pca = prcomp(x_train)
  prop = cumsum(pca$sdev^2)/sum(pca$sdev^2)
  for (Q in 2:30){
    xz_train = pca$x[,1:Q]
    data_train = data.frame(y_train, xz_train)
    
    fit = multinom(y_train ~ ., data = data_train, trace = FALSE)
    xz_validation = predict(pca, x_validation)[,1:Q]
    
    predictions = predict(fit, newdata = data.frame(xz_validation))
    
    accuracy_matrix[k,Q] = mean(predictions == y_validation)
    
  }
}
```

The data is split into **5 folds**, and for each fold, the model is trained on **4 folds** and validated on the **remaining fold**. **PCA** is fitted to the training data, and the model is trained on the first **Q principal components**. The **accuracy** of the model is computed on the validation set for each **Q** (number of principal components) from **2 to 30**. The accuracy scores are stored in an **accuracy_matrix** for each fold and **Q**.

```{r}
Q_Values = colMeans(accuracy_matrix)
best_q = 0
for (q in 2:30){
  if(prop[q] >= 0.80 && prop[q] <= 0.90) {
    best_q = q
    break
  }
}
cat("Explained Variance: ", prop[best_q])
cat("\nAccuracy: ", Q_Values[best_q])
cat("\nBest q values is:", best_q)
```

## Neural Network - Tuning Number of one hidden layer neurons.

```{r, warning=FALSE}
library(keras)
tensorflow::set_random_seed(101)
```

**h_vec** contains the number of hidden units to test (5, 10, 15, 20, 25, 30, 35).

```{r}
h_vec = c(5, 10, 15, 20, 25, 30, 35)
H = length(h_vec)
```

We performs **5 iterations** of training a **neural network** with varying hidden units (5 to 35) using **80% of the data for training** and **20% for validation**, storing the training and validation accuracy for each configuration.

```{r, warning=FALSE, message=FALSE, results='hide'}
B = 5
acc_train = acc_val = matrix(NA, B, H)

#One hot encoding
y_factor = data_train_and_validation[,1]
y_numeric <- as.numeric(y_factor) -1
y_one_hot <- to_categorical(y_numeric)
K = ncol(y_one_hot)

for (b in 1:B) {
  
  neu_train = sample(1:n_train, n_train * 0.8)
  length(neu_train)
  neu_val = setdiff(1:n_train, neu_train)
  any(is.na(neu_train))
  any(is.na(neu_val))
  x_train = as.matrix(data_train_and_validation[neu_train,-1])
  y_train <- to_categorical(as.numeric(data_train_and_validation[neu_train,1])-1)
  nrow(y_train)
  x_val <- as.matrix(data_train_and_validation[neu_val,-1])
  y_val <- to_categorical(as.numeric(data_train_and_validation[neu_val,1])-1)
  
  V = ncol(x_train)
  
  for( h in 1:H){
    model = keras_model_sequential()
    model |> 
    layer_dense(units = h_vec[h], activation = "relu", input_shape = V) |>
    layer_dense(units = K, activation = "softmax") |>
    compile(
      loss = "categorical_crossentropy",
      optimizer = optimizer_sgd(),
      metrics = "accuracy"
    )
  fit = model |> fit(x=x_train, y=y_train, 
                     validation_data = list(x_val,y_val), epochs=10)
  
  #storing accuracy
  n_epoch = fit$params$epochs
  
  #storing accuracy of last iteration
  acc_train[b,h] = fit$metrics$accuracy[n_epoch]
  acc_val[b,h] = fit$metrics$val_accuracy[n_epoch]
  }
}
```

**Categorical cross-entropy** is used as the loss function because it is specifically designed for **multi-class classification tasks**, effectively measuring the difference between predicted probabilities and true class labels.

**Justification for using Relu and softmax activation function:**

-   The **ReLU** activation function in the hidden layers **avoids vanishing gradients**, **enables faster convergence**, and **introduces sparsity**, improving training efficiency and generalization.

-   The **softmax** function in the output layer **produces probabilities** for the 4 bat families, making it ideal for **multi-class classification**.

-   Together, **ReLU** and **softmax** ensure the model **learns complex patterns effectively**

The results are stored in **acc_train** and **acc_val** matrices for analysis.

We take **mean** value of **each** **column** in **acc_train** and **acc_val** to plot graph between **accuracy** and **number of one hidden layer neurons**.

```{r}
mean_acc_train = colMeans(acc_train)
mean_acc_val = colMeans(acc_val)

matplot(x = h_vec, mean_acc_train, type = "l", lty = 1, 
        ylab = "Accuracy", xlab = "H",col = adjustcolor("black", 0.8))
matplot(x = h_vec, mean_acc_val, type = "l", lty = 1,
        col = adjustcolor("darkorange2", 0.9), add = TRUE)
```

We use **elbow method** to choose **20 hidden units** because the accuracy improvement plateaus after this point. This balances model complexity and performance effectively.

**Selecting the best model between Multinomial Logistic Regression and Neural Network with tuned parameters:**

Here, we perform **10 repetitions (R = 10)** of **5-fold cross-validation** to compare the performance of a **multinomial logistic regression model with PCA** and a **neural network** with **20 hidden units**. For each fold, the data is split into training and validation sets, and both models are trained and evaluated. The **accuracy** of each model is stored in **accuracy_matrix_multinomial_final** and **accuracy_matrix_nnet_final** for comparison.

```{r, warning=FALSE, message=FALSE, results='hide'}
K = 5
R=10
number_of_hidden_layer_neurons = 20
accuracy_matrix_multinomial_final = matrix(0, nrow = R, ncol = K)
accuracy_matrix_nnet_final = matrix(0, nrow = R, ncol = K)

for( r in 1:R) {
  folds = rep(1:K, ceiling(n_train/K))
  folds = sample(folds)
  folds = folds[1:n_train]
  for (k in 1:K) {
      k_train = which(folds != k)
      k_validation = setdiff(1:n_train, k_train)
      
      x_train = data_train_and_validation[k_train,-1]
      y_train = data_train_and_validation[k_train,1]
      y_train = as.factor(y_train)
      
      x_validation = data_train_and_validation[k_validation,-1]
      y_validation = data_train_and_validation[k_validation,1]
      y_validation = as.factor(y_validation)
    
      pca = prcomp(x_train)
      prop = cumsum(pca$sdev^2)/sum(pca$sdev^2)
      xz_train = pca$x[,1:best_q]
      data_train = data.frame(y_train, xz_train)
      fit = multinom(y_train ~ ., data = data_train, trace = FALSE)
      xz_validation = predict(pca, x_validation)[,1:best_q]
      predictions = predict(fit, newdata = data.frame(xz_validation))
      accuracy_matrix_multinomial_final[r,k] = mean(predictions == y_validation)
    
      x_train = as.matrix(x_train)
      y_train <- to_categorical(as.numeric(y_train)-1)
      x_val <- as.matrix(x_validation)
      y_val <- to_categorical(as.numeric(y_validation)-1)
      
      model = keras_model_sequential()
      model |> 
      layer_dense(units = number_of_hidden_layer_neurons, 
                  activation = "relu", 
                  input_shape = ncol(x_train)) |>
      layer_dense(units = ncol(y_val), activation = "softmax") |>
      compile(
        loss = "categorical_crossentropy",
        optimizer = optimizer_sgd(),
        metrics = "accuracy"
      )
    
      fit = model |> fit(x=x_train, y=y_train, 
                         validation_data = list(x_val,y_val), epochs=10)
      
      n_epoch = fit$params$epochs
    
      accuracy_matrix_nnet_final[r,k] = fit$metrics$val_accuracy[n_epoch]
  }
}  
```

```{r}
cat("Accuracy of Multinomial Regression is: ",
    max(colMeans(accuracy_matrix_multinomial_final)))
```

```{r}
cat("Accuracy of Neural Network is: ",
    max(colMeans(accuracy_matrix_nnet_final)))
```

The **neural network** beats the **multinomial logistic regression model** in **high accuracy** due to the **superior learning capacity** of neural networks to capture **non-linear relationships** and **complex patterns** within the data, making it appropriate for tasks such as the classification of bat families, where acoustic features may show **complex relationships**. The **ReLU activation** and the **softmax output** enhance the ability of the neural network to model **multi-class classification efficiently**.

# Q2.

## Evaluating the generalized predictive performance of the selected model by assessing its accuracy on some appropriately prepared test data.

Since, we got high accuracy in Neural network with one hidden layer containing 20 neurons, we evaluate the predictive performance of the selected model by assessing its accuracy with test data.

```{r, warning=FALSE, message=FALSE, results='hide'}
#Training model with whole data
full_x_train = as.matrix(data_train_and_validation[,-1])
full_y_train = to_categorical(as.numeric(data_train_and_validation[,1])-1)

x_test = as.matrix(data_test[,-1])
y_test = to_categorical(as.numeric(data_test[,1])-1)

      
model = keras_model_sequential()
model |> 
  layer_dense(units = number_of_hidden_layer_neurons, activation = "relu", 
              input_shape = ncol(full_x_train)) |>
  layer_dense(units = ncol(y_test), activation = "softmax") |>
  compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_sgd(),
    metrics = "accuracy"
    )
    
fit = model |> fit(x=full_x_train, y=full_y_train, 
                   validation_data = list(x_test,y_test), epochs=10)
      
n_epoch = fit$params$epochs
  
accuracy_final = fit$metrics$val_accuracy[n_epoch]
```

```{r}
cat("Accuracy of neural network on test data: ",accuracy_final)
```

We filters **data_test** to include only **emba** family data, prepares the input **x_test_emba** and one-hot encoded output y_test_emba, and evaluates the model on this subset. The validation accuracy for the **emba** family is extracted from the last epoch and stored in **accuracy_final_emba**.

```{r, warning=FALSE, message=FALSE, results='hide'}
data_test_emba = data_test[data_test[,1] == "emba", ]

x_test_emba = as.matrix(data_test_emba[,-1])
y_test_emba = to_categorical(as.numeric(data_test_emba[,1])-1)

fit_emba = model |> fit(x=full_x_train, y=full_y_train, 
        validation_data = list(x_test_emba,y_test_emba), epochs=10)
      
n_epoch = fit_emba$params$epochs
  
accuracy_final_emba = fit_emba$metrics$val_accuracy[n_epoch]
```

```{r}
cat("Accuracy in predicting the family emba: ", accuracy_final_emba)
```

Interpretations:

-   The model achieves an accuracy of around **88%** on the **emba** family, which is consistent with its overall test accuracy.

-   This indicates that the model performs well in predicting the **Emballonuridae** family, effectively capturing its unique acoustic features.
